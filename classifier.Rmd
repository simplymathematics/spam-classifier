---
title: "DATA 607 Project 4"
author: simplymathematics
date: "November 2, 2018"
output: html_document
---

```
PROJECT 4: Document Classification
It can be useful to be able to classify new "test" documents using already classified "training" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.  

For this project, you can start with a spam/ham dataset, then predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder). 
```
# Dependencies
As always, we start with dependencies
```{r}
require(tm)
require(tidyverse)
require(e1071)
require(mlr)
```

Here, we gather our data
```{r}
file.path <- c("easy_ham/", "spam/", "spam_2/", "spam_3/")
```

#Data Cleaning:

First I read each file into a corpus using the ```tm``` package.
```{r}
spam <- file.path[2] %>% DirSource() %>% VCorpus() 
ham <- file.path[1] %>% DirSource() %>% VCorpus()
test <- file.path[3] %>% DirSource() %>% VCorpus()
spam
ham
test
```

Then, we had to clean each email. So, I made a function that could do it for each type.

```{r}
list <- c("date", "deliveredto", "received", "subject", "localhost", "returnpath")
clean <- function(tmp){
    tmp <- tmp %>% tm_map(content_transformer(PlainTextDocument))
    tmp <- tmp %>% tm_map(content_transformer(function(x) gsub(x, pattern="[^a-zA-Z/d/s:]", replacement=" "))) #deletes all weird symbols
    tmp <- tmp %>% tm_map(content_transformer(function(x) iconv(enc2utf8(x), sub = "byte")))
    tmp <- tmp %>% tm_map(removePunctuation) #remove punctuation
    tmp <- tmp %>% tm_map(removeNumbers)     #remove numbers
    tmp <- tmp %>% tm_map(content_transformer(tolower)) #change to low case
    tmp <- tmp %>% tm_map(stemDocument) #truncates words to remove word endings and reduce our library set
    tmp <- tmp %>% tm_map(content_transformer(function(x) removeWords(x, words = list)))
    tmp <- tmp %>% tm_map(removeWords, stopwords('english'))
    return(tmp)
}
```

Then, we make a vector, both, that contains both.
```{r}
clean.ham <- ham %>% clean()
clean.spam <- spam %>% clean()
clean.test <- test %>% clean()
```
Next, I created a document term matrix and removed sparse terms for the whole set, the ham set, and the spam set.
```{r}
sparsity = .93 #picked through testing such that in maximizes the distance between ham and spam
final.ham <- clean.ham %>% DocumentTermMatrix() %>% removeSparseTerms(sparsity)
final.spam <- clean.spam %>% DocumentTermMatrix() %>% removeSparseTerms(sparsity)
final.test <- clean.test %>% DocumentTermMatrix() %>% removeSparseTerms(sparsity)
```
Finally, I made a matrix for each frequency table.
```{r}
# Ham
ham.freq <- final.ham %>% as.matrix %>% colSums() %>% as.data.frame() %>% rownames_to_column("string")
colnames(ham.freq) <- c('string', 'count')

# Spam
spam.freq <- final.spam %>% as.matrix %>% colSums() %>% as.data.frame() %>% rownames_to_column("string")
colnames(spam.freq) <- c('string', 'count')

#Test
test.freq <- final.test %>% as.matrix %>% colSums() %>% as.data.frame() %>% rownames_to_column("string")
colnames(test.freq) <- c('string', 'count')
```
Then, I merged the tables and converted the 'NAs' to 0. 
```{r}
# Ham and Spam 1
table <- merge(x = ham.freq, y = spam.freq, by = 'string', all.x = TRUE)
table <- table %>% mutate_all(funs(replace(., is.na(.), 0))) %>% as.data.frame()
colnames(table) <- c('string', 'ham.count', 'spam1.count')
row.names(table) <- NULL


# Ham, Spam 1, and Spam 2
table2 <- merge(x = table, y = test.freq, by = 'string', all.x = TRUE)
table2 <- table2 %>% mutate_all(funs(replace(., is.na(.), 0))) %>% as.data.frame()
colnames(table2) <- c('string', 'ham.count', 'spam1.count', 'spam2.count')
row.names(table2) <- NULL



```

## An Example Implementation
Below we've implemented an example classifier that tests a file from the spam 2 folder. In this case it is successful, but the correlation values are very close. Therefore, this model may be over-fitting. Perhaps we can do better below.
```{r}
foo <- file.path[4] %>% DirSource() %>% VCorpus()
foo <- foo %>% clean()
foo <- foo %>% DocumentTermMatrix() 
foo <- foo %>% as.matrix %>% colSums() %>% as.data.frame() %>% rownames_to_column("string")
colnames(foo) <- c('string', 'test.case')
table3 <- merge(x = table, y = foo, by = 'string', all.x=TRUE)
table3 <- table3 %>% mutate_all(funs(replace(., is.na(.), 0))) %>% as.data.frame()
a <- cor(table3$ham.count, table3$test.case)
b <- cor(table3$spam1.count, table3$test.case)
if (a > b){
  print("test case is not spam")
} else if (a == b){
  print("we cannot draw a conclusion")
} else{
  print("test case is spam")
}

```
Next, I did a $\chi^2$-test to see if the there was a significant difference between these two categories with the parameters set above.
```{r}
value1 <- chisq.test(table$ham.count, table$spam1.count)
value2 <- chisq.test(table2$ham.count, table2$spam2.count)
value3 <- chisq.test(table2$spam1.count, table2$spam2.count)
value1
value2
value3
```
As we can see from the test, a naive chi-square test of the word frequencies can work as a classifier. To accomodate this test, I labelled and combined the spam and ham data, storing the result in a dataframe called 'both.' Each row contains a frequency table for various terms and a final column called 'status' that indicates whether the email is spam or not (TRUE or FALSE respectively.)

```{r}
final.ham$status <- rep("FALSE", nrow(final.ham))
final.ham <- final.ham %>% as.matrix() %>% data.frame()
final.spam$status <- rep("TRUE", nrow(final.spam))
final.spam <- final.spam %>% as.matrix() %>% data.frame()
final.test$status <- rep("TRUE", nrow(final.test))
final.test <- final.test %>% as.matrix() %>% data.frame()
final.test
  
both <- merge(final.ham, final.spam, all=TRUE)
both <- both %>% as.matrix() %>% data.frame()
final.test <- final.test %>% as.matrix() %>% data.frame()
final.both merge(both, final.test, all=)
head(both)
```
As we saw above, this particular set of terms is sufficient evidence to parse spam from ham. Therefore, the naive bayes model is appropriate. Below, I trained a model using the spam 1 dataset.

```{r}
task = makeClassifTask(data = both, target = "status")
trainer = makeLearner("classif.naiveBayes")
trained = train(trainer, task)
```

Below is the naive bayes classifier model for each keyword we found. However, further implementation will require cleaning the data and looking only for the keywords deemed important by this model.
```{r}
trained$learner.model
```

```{r}
#predict(trained$learner.model, task = task, subset = foo)```
#Read the model learned  
NB_mlr$learner.model
 
#Predict on the dataset without passing the target feature
predictions_mlr = as.data.frame(predict(NB_mlr, newdata = Titanic_dataset[,1:3]))
 
##Confusion matrix to check accuracy
table(predictions_mlr[,1],Titanic_dataset$Survived)
